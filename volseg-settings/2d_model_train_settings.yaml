# Settings for image and model output
data_im_dirname: data # Name of folder that sliced data 2D images will be output to
seg_im_out_dirname: seg # Name of folder that sliced segmentation 2D images with be output to 
model_output_fn: trained_2d_model # Suffix for the saved model filename
data_hdf5_path: /data # The internal HDF5 path to the image data
seg_hdf5_path: /data # The internal HDF5 path to the label data

#Normalisation settings
clip_data: True # Clip and rescale the image data intensities before saving to disk
st_dev_factor: 2.575 # The number of standard deviations from the mean to clip data to
minmax_norm: False # Min-max normalisation/rescaling. Only needed if clip_data if False.
use_imagenet_norm: True # If True, applies ImageNet mean/std normalisation to input images (wanted if Imagenet pretrained weights used)
normalization_debug_mode: False # If True, enables detailed normalisation debugging in training loop

# Augmentation settings
augmentation_library: albumentations # Choose augmentation library: "albumentations" or "monai"
use_monai_datasets: true # Use MONAI datasets when using MONAI augmentations (default: true when augmentation_library is monai)

# Multi-task learning settings (requires MONAI datasets)
use_multitask: false # Enable multi-task learning (requires MONAI datasets)
num_tasks: 2 # Number of tasks: 2 (seg + boundary) or 3 (seg + boundary + task3)
decoder_sharing: "shared" # Decoder sharing strategy: "shared" (all heads share one decoder) or "separate" (each head has its own decoder)
# Multi-task loss weights 
seg_loss_weight: 1.0 # Weight for segmentation loss
boundary_loss_weight: 1.0 # Weight for boundary loss
task3_loss_weight: 1.0 # Weight for task3 loss (if num_tasks = 3)
boundary_loss_type: "bce" # Boundary loss type: "bce", "dice", or "bce_dice"

# Loss selection
loss_criterion: "CombinedCEDiceLoss"  # or "ClassWeightedDiceLoss"
# Dice weighting
dice_weight_mode: "inverse_sqrt_freq"  # or "inverse_freq", "uniform"
exclude_background_from_dice: False     # Usually true for foreground structures
# For CombinedCEDiceLoss
ce_weight: 0.2   # Weight for Cross-Entropy
dice_weight: 0.8 # Weight for Dice
# Evaluation
dice_averaging: "macro"  # or "weighted"


# 2.5D slicing settings
use_2_5d_slicing: False # If True, enables 2.5D slicing with configurable number of slices
num_slices: 3 # Number of slices to use (must be odd: 3, 5, 7, 9, etc.)
slice_file_format: "png" # File format for multi-channel slices: "tiff" (default) or "png" (only for 3 channels or less)
skip_border_slices: False # If True, skips first and last slices when using 2.5D slicing

# Settings for model training
training_axes: All # Specify axes/single axis to train on. Choose from [All, Z, X, Y]. 
image_size: 256 # size of images used for training (must be multiple of 32)
downsample: False # If True, data will be downsampled by 2
training_set_proportion: 0.85 # Proportion of images to use the training, rest are used for validation
cuda_device: 0 # The graphics card to use (between 0 and 3 for a machine with 4 GPUs)
num_cyc_frozen: 8 # Number of training epochs on frozen model
num_cyc_unfrozen: 5 # Number of training epochs on unfrozen model
patience: 4 # Number of epochs to wait before early stopping if validation loss does not improve

loss_criterion: "DiceLoss" # Choose from one of [BCEDiceLoss, BCELoss, DiceLoss, GeneralizedDiceLoss, CrossEntropyLoss, TverskyLoss, BoundaryDoULoss, BoundaryLoss]
alpha: 0.5 # When BCEDiceLoss selected, weighting for BCELoss
beta: 0.5 # When BCEDiceLoss selected, weighting for DiceLoss
eval_metric: "DiceCoefficient" # Choose from one of [MeanIoU, DiceCoefficient]
pct_lr_inc: 0.3 # the percentage of overall iterations where the LR is increasing
# Parameters for finding learning rate
starting_lr: 5e-5 # Lower bound of learning rate search
end_lr: 1e-3 # Upper Bound of learning rate search

# Semi-supervised learning settings
use_semi_supervised: False  # Enable semi-supervised training (Mean Teacher)
unlabeled_data_dir: ""  # Path to directory with unlabeled image slices
unlabeled_batch_size: 8  # Batch size for unlabeled data (can differ from labeled)
consistency_weight: 0.1  # Maximum weight for consistency loss (ramped up from 0)
rampup_start: 0  # Start ramp-up at this iteration
rampup_end: 10000  # End ramp-up at this iteration
ema_decay: 0.99  # EMA decay rate (0.99 is standard)

# Pseudo-labeling semi-supervised learning settings
use_pseudo_labeling: False  # Enable pseudo-labeling (can be combined with Mean Teacher)
pseudo_label_confidence_threshold: 0.95  # Minimum confidence to accept pseudo-label (0.0-1.0)
pseudo_label_confidence_method: "max_prob"  # Confidence method: "max_prob", "entropy", "per_class"
pseudo_label_min_pixels_per_class: 10  # Minimum pixels per class to accept pseudo-label
pseudo_label_use_teacher: True  # Use teacher model for pseudo-label generation (if Mean Teacher enabled)
pseudo_label_weight: 1.0  # Weight for pseudo-label loss
pseudo_label_rampup_start: 0  # Start ramp-up at this iteration
pseudo_label_rampup_end: 5000  # End ramp-up at this iteration
pseudo_label_threshold_schedule: "fixed"  # Threshold schedule: "fixed", "linear", "cosine", "adaptive"
pseudo_label_start_threshold: 0.9  # Starting threshold (for scheduling)
pseudo_label_target_acceptance_rate: 0.3  # Target acceptance rate (for adaptive scheduling)

# Misc training settings
lr_find_epochs: 1 # Number of training epochs for learning rate search
lr_reduce_factor: 500 # Divisor for start and end LR when finding LR on reloaded model
plot_lr_graph: False # Set to True if gnuplot is installed and a terminal plot of learning rate is required 
use_sam: False
adaptive_sam: True
encoder_weights_path: False
#encoder_weights_path: "/somewhere/improved-resnet4.pt"
full_weights_path: False

# Parameters to control model architecture
model:
  # Choose type of segmentation model from the list of those tested so far
  # ["U_Net", "U_Net_Plus_plus", "FPN", "DeepLabV3", "DeepLabV3_Plus"]
  # "MA_Net", "Linknet", "PAN", "Segformer", "Multitask_Unet"]
  # Note: Use "Multitask_Unet" when use_multitask is true
  type: "U_Net"
  # For more details on encoder types please see smp.readthedocs.io
  # choose encoder, those tested so far include the following:
  # ["resnet34", "resnet50", "tu-convnextv2_base", "tu-convnextv2_large", "tu_convnext_base", "tu_convnext_large"
  # "resnext50_32x4d", "efficientnet-b3","efficientnet-b4", "efficientnet-b5", "efficientnet-b7"
  # "timm-resnest50d"*, "timm-resnest101e"*,] *Encoders with asterisk not compatible with PAN.
  encoder_name: "tu-convnextv2_base"
   # use `imagenet` pre-trained weights for encoder initialization
  encoder_weights: "imagenet"
  
